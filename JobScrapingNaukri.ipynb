{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd574fb-bb76-4e18-b439-a363e0e15b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2327304-cd22-44c1-9746-947a124063ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Selenium to use Chrome\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# Set up the Chrome WebDriver (using webdriver_manager to handle the driver automatically)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# Base URL for Naukri data engineer job search\n",
    "# base_url = \"https://www.naukri.com/data-engineer-jobs?k=data+engineer&experience=5\"\n",
    "# base_url = \"https://www.naukri.com/data-engineer-jobs-in-hyderabad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ee0652-ac13-4870-9ffd-bffde040e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get job data from a single page\n",
    "def get_job_data(page_number):\n",
    "    \n",
    "    # url = f\"{base_url}-{page_number}?l=hyderabad&experience=5\"\n",
    "    \n",
    "    url = f\"https://www.naukri.com/data-engineer-jobs-in-hyderabad-{page_number}?experience=5\"\n",
    "\n",
    "    driver.get(url)  # Open the webpage\n",
    "    \n",
    "    time.sleep(3)  # Wait for JavaScript to load content (adjust sleep time if necessary)\n",
    "    \n",
    "    job_cards = driver.find_elements(By.CLASS_NAME, \"srp-jobtuple-wrapper\")  # Locate job listing elements by class name\n",
    "    \n",
    "    job_titles = []\n",
    "    company_names = []\n",
    "    locations = []\n",
    "    experience = []\n",
    "    posted_dates = []\n",
    "    salary = []\n",
    "    skills = []\n",
    "    \n",
    "    # Loop through each job card and extract details\n",
    "    for job in job_cards:\n",
    "        try:\n",
    "            title = job.find_element(By.CLASS_NAME, \"title\").text   \n",
    "        except:\n",
    "            title = \"No Title\"\n",
    "        \n",
    "        try:\n",
    "            company = job.find_element(By.CLASS_NAME, 'comp-name').text\n",
    "        except:\n",
    "            company = \"No Company\"\n",
    "        \n",
    "        try:\n",
    "            location = job.find_element(By.CLASS_NAME, 'loc-wrap').text\n",
    "        except:\n",
    "            location = \"No Location\"\n",
    "        \n",
    "        try:\n",
    "            exp = job.find_element(By.CLASS_NAME, 'exp-wrap').text\n",
    "        except:\n",
    "            exp = \"No Experience\"\n",
    "        \n",
    "        try:\n",
    "            date = job.find_element(By.CLASS_NAME, 'job-post-day').text\n",
    "        except:\n",
    "            date = \"No Date\"\n",
    "\n",
    "        try:\n",
    "            sal = job.find_element(By.CLASS_NAME, 'sal-wrap').text\n",
    "        except:\n",
    "            sal = \"NAN\"\n",
    "\n",
    "        try:\n",
    "            skill_tag = job.find_element(By.CLASS_NAME, 'tags-gt')\n",
    "            skill_list = []\n",
    "            \n",
    "            for child in  skill_tag.find_elements(By.TAG_NAME, 'li'):\n",
    "            #     print(\"here\")\n",
    "            #     print(child.text)\n",
    "                skill_list.append(child.text.strip().lower())\n",
    "\n",
    "            skill = \",\".join(skill_list)\n",
    "            \n",
    "        except:\n",
    "            skill = \"NAN\"\n",
    "        \n",
    "        \n",
    "        job_titles.append(title)\n",
    "        company_names.append(company)\n",
    "        locations.append(location)\n",
    "        experience.append(exp)\n",
    "        posted_dates.append(date)\n",
    "        salary.append(sal)\n",
    "        skills.append(skill)\n",
    "    \n",
    "    # Return the extracted data as a dictionary\n",
    "    job_data = {\n",
    "        \"Job Title\": job_titles,\n",
    "        \"Company\": company_names,\n",
    "        \"Location\": locations,\n",
    "        \"Experience\": experience,\n",
    "        \"Date Posted\": posted_dates,\n",
    "        \"Salary\": salary,\n",
    "        \"Skills\": skills\n",
    "    }\n",
    "    \n",
    "    return job_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36565600-ad34-4764-a9ec-0409d50e5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape multiple pages\n",
    "def scrape_naukri_jobs(max_pages):\n",
    "    all_jobs = []\n",
    "    \n",
    "    for page_number in range(1, max_pages + 1):\n",
    "        print(f\"Scraping page {page_number}...\")\n",
    "        job_data = get_job_data(page_number)\n",
    "        \n",
    "        if job_data:\n",
    "            all_jobs.append(job_data)\n",
    "        \n",
    "        # Wait a bit between requests to avoid overwhelming the server\n",
    "        time.sleep(3)\n",
    "    \n",
    "    return all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598786a3-f448-488a-b481-6c9d7df25ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Scraping page 36...\n",
      "Scraping page 37...\n",
      "Scraping page 38...\n",
      "Scraping page 39...\n",
      "Scraping page 40...\n",
      "Scraping page 41...\n",
      "Scraping page 42...\n",
      "Scraping page 43...\n",
      "Scraping page 44...\n",
      "Scraping page 45...\n",
      "Scraping page 46...\n",
      "Scraping page 47...\n",
      "Scraping page 48...\n",
      "Scraping page 49...\n",
      "Scraping page 50...\n",
      "Scraped data saved to 'data_engineer_jobs_naukri.csv'\n",
      "                                Job Title  \\\n",
      "0                           Data Engineer   \n",
      "1                           Data Engineer   \n",
      "2                           Data Engineer   \n",
      "3                Python and Data Engineer   \n",
      "4  Data Engineer (IICS, ETL, Informatica)   \n",
      "\n",
      "                                             Company  \\\n",
      "0                                          Accenture   \n",
      "1  CGI Information Systems And Management Consult...   \n",
      "2                                   Trigent Software   \n",
      "3                                      Tech Mahindra   \n",
      "4                                                 EY   \n",
      "\n",
      "                              Location Experience  Date Posted  \\\n",
      "0                            Hyderabad    3-8 Yrs   4 Days Ago   \n",
      "1                 Hyderabad, Bengaluru    5-8 Yrs   6 Days Ago   \n",
      "2                 Hyderabad, Bengaluru    4-8 Yrs  10 Days Ago   \n",
      "3  Hybrid - Hyderabad, Pune, Bengaluru   5-10 Yrs  13 Days Ago   \n",
      "4                            Hyderabad    4-9 Yrs   2 Days Ago   \n",
      "\n",
      "            Salary                                             Skills  \n",
      "0    Not disclosed  software testing,dbms,sql,jcl,cobol,data analy...  \n",
      "1  17-22.5 Lacs PA           pyspark,python,sql,data engineering,data  \n",
      "2    15-30 Lacs PA  aws cloud,scala,sql database,distributed data ...  \n",
      "3    12-22 Lacs PA  pyspark,docker,scala,devops,python,apache hop,...  \n",
      "4    Not disclosed  iics,informatica intelligent cloud services,in...  \n"
     ]
    }
   ],
   "source": [
    "# Scrape data from multiple pages\n",
    "job_data_list = scrape_naukri_jobs(max_pages=50)  # Change max_pages as needed\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "if job_data_list:\n",
    "    # Flatten the list of dictionaries into one DataFrame\n",
    "    all_jobs_df = pd.DataFrame(job_data_list[0])\n",
    "    for job_data in job_data_list[1:]:\n",
    "        temp_df = pd.DataFrame(job_data)\n",
    "        all_jobs_df = pd.concat([all_jobs_df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    all_jobs_df.to_csv('data_engineer_jobs_naukri.csv', index=False)\n",
    "    print(\"Scraped data saved to 'data_engineer_jobs_naukri.csv'\")\n",
    "    print(all_jobs_df.head())  # Display the first few rows of the data\n",
    "else:\n",
    "    print(\"No job data scraped.\")\n",
    "\n",
    "# Close the Selenium WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5937736-bd79-4a8e-a24a-11f91744f0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
